{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, sys, numpy, os, time\n",
    "datasets = 'datasets'  \n",
    "(width, height) = (130, 100)  \n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "model = cv2.face.LBPHFaceRecognizer_create() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainData():\n",
    "    # Create a list of images and a list of corresponding names\n",
    "    print(\"Training the data....\")\n",
    "    (images, lables, names, ids) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(datasets):\n",
    "        for subdir in dirs:\n",
    "            \n",
    "            names[ids] = subdir\n",
    "            subjectpath = os.path.join(datasets, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = ids\n",
    "                images.append(cv2.imread(path, 0))\n",
    "                lables.append(int(lable))\n",
    "            ids += 1\n",
    "\n",
    "\n",
    "    # Create a Numpy array from the two lists above\n",
    "    (images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "\n",
    "    # OpenCV trains a model from the images\n",
    "    # NOTE FOR OpenCV2: remove '.face'    \n",
    "    model.train(images, lables)\n",
    "    print('Training completed..')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureNewFace():\n",
    "    \n",
    "    print(\"Your entering frame your ready to give pictures press: q \")\n",
    "\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    \n",
    "    while(webcam.isOpened()):\n",
    "            ret, frame = webcam.read()\n",
    "\n",
    "            if ret == True:\n",
    "                # Display the resulting frame\n",
    "                cv2.imshow('Frame', frame)\n",
    "\n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    webcam.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "def takepics():\n",
    "    \n",
    "    sub_data = input(\"Enter your name: \")\n",
    "    path = os.path.join(datasets, sub_data)\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        print(\"started capture face....\")\n",
    "        \n",
    "        count = 1\n",
    "        \n",
    "        # The program loops until it has 50 images of the face.    \n",
    "\n",
    "        while count < 50:\n",
    "\n",
    "            ret, frame  = webcam.read()\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)      \n",
    "\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(gray, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                face = gray[y:y + h, x:x + w]\n",
    "                face_resize = cv2.resize(face, (width, height))\n",
    "                cv2.imwrite('% s/% s.png' % (path, count), face_resize)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            cv2.imshow('OpenCV', gray)\n",
    "            \n",
    "            # sleep time 0.30sec(10 pics in 3 sec)\n",
    "            # sleep time 0.50sec(10 pics in 5 sec )\n",
    "            time.sleep(0.30)\n",
    "            \n",
    "        print(\"Completed....\")\n",
    "                \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An exception occurred: \",e,sys.exc_info()[0])\n",
    "    finally:\n",
    "        webcam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        trainData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureTestVideo():\n",
    "    # Part 1: Create fisherRecognizer\n",
    "    print('Recognizing Face Please Be in sufficient Lights...')\n",
    "    #Capture video from webcam\n",
    "    vid_capture = cv2.VideoCapture(0)\n",
    "    frame_width = int(vid_capture.get(3))\n",
    "    frame_height = int(vid_capture.get(4))\n",
    "\n",
    "    size = (frame_width, frame_height)\n",
    "    output = cv2.VideoWriter('videos/input.avi', cv2.VideoWriter_fourcc(*'MJPG'), 20.0, size)\n",
    "    while(True):\n",
    "         # Capture each frame of webcam video\n",
    "         ret,frame = vid_capture.read()\n",
    "         cv2.imshow(\"My cam video\", frame)\n",
    "         output.write(frame)\n",
    "         # Close and break the loop after pressing \"x\" key\n",
    "         if cv2.waitKey(1) &0XFF == ord('x'):\n",
    "             break\n",
    "    # close the already opened camera\n",
    "    vid_capture.release()\n",
    "    # close the already opened file\n",
    "    output.release()\n",
    "    # close the window and de-allocate any associated memory usage\n",
    "    cv2.destroyAllWindows()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizeFace():\n",
    "    (images, lables, names, ids) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(datasets):\n",
    "        for subdir in dirs:\n",
    "            \n",
    "            names[ids] = subdir\n",
    "            subjectpath = os.path.join(datasets, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = ids\n",
    "                #images.append(cv2.imread(path, 0))\n",
    "                #lables.append(int(lable))\n",
    "            ids += 1\n",
    "            \n",
    "    isRecognised=False\n",
    "    vidcap = cv2.VideoCapture('videos/input.avi')\n",
    "    if (vidcap.isOpened()== False): \n",
    "      print(\"Error opening video  file\")\n",
    "      return False\n",
    "    \n",
    "    while(vidcap.isOpened()):\n",
    "          # Capture frame-by-frame     \n",
    "        \n",
    "        success, im = vidcap.read()\n",
    "        if success == True:\n",
    "            gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                face = gray[y:y + h, x:x + w]\n",
    "                face_resize = cv2.resize(face, (width, height))\n",
    "                # Try to recognize the face\n",
    "                prediction = model.predict(face_resize)\n",
    "                cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "                if prediction[1]<100:  \n",
    "                   isRecognised = True\n",
    "                   print(names[prediction[0]])\n",
    "                   print(prediction)\n",
    "                   return isRecognised  \n",
    "        else: \n",
    "            break\n",
    "\n",
    "        # When everything done, release \n",
    "        # the video capture object\n",
    "    vidcap.release()\n",
    "\n",
    "     # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    return isRecognised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyLive():\n",
    "    (images, lables, names, ids) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(datasets):\n",
    "        for subdir in dirs:\n",
    "            \n",
    "            names[ids] = subdir\n",
    "            subjectpath = os.path.join(datasets, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = ids\n",
    "                #images.append(cv2.imread(path, 0))\n",
    "                #lables.append(int(lable))\n",
    "            ids += 1\n",
    "            \n",
    "            \n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        (success, im) = webcam.read()\n",
    "        if success == True:\n",
    "            gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                face = gray[y:y + h, x:x + w]\n",
    "                face_resize = cv2.resize(face, (width, height))\n",
    "                # Try to recognize the face\n",
    "                prediction = model.predict(face_resize)\n",
    "                cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "                if prediction[1]<70:\n",
    "                   cv2.putText(im, '% s - %.0f' % (names[prediction[0]], prediction[1]), (x-10, y-10),cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
    "                else:\n",
    "                  cv2.putText(im, 'Unknown', (x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
    "\n",
    "            cv2.imshow('OpenCV', im)\n",
    "\n",
    "        if cv2.waitKey(1) &0XFF == ord('x'):\n",
    "            break\n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your entering frame your ready to give pictures press: q \n",
      "Training the data....\n",
      "Training completed..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fb676ef059cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#captureTestVideo()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(recognizeFace())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0midentifyLive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-7cdfb20b8deb>\u001b[0m in \u001b[0;36midentifyLive\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trainData()\n",
    "captureNewFace()\n",
    "takepics()\n",
    "trainData()\n",
    "#captureTestVideo()\n",
    "#print(recognizeFace())\n",
    "identifyLive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
